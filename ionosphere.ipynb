{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.nn import Module\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import BCELoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.optim import SGD\n",
    "from numpy import vstack\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch import Tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset definition\n",
    "PyTorch provides the Dataset class that you can extend and customize to load your dataset.\n",
    "For example, the constructor of your dataset object can load your data file (e.g. a CSV file). You can then override the __len__() function that can be used to get the length of the dataset (number of rows or samples), and the __getitem__() function that is used to get a specific sample by index.\n",
    "\n",
    "The random_split() function can be used to split a dataset into train and test sets. Here we are dividing 67 train and 33 test data.\n",
    "\n",
    "##### Current CSVDataset\n",
    "label is the last one in the csv. It is a string represented as 'g': good and 'b': bad.\n",
    "We use LabelEncoder to encode string labels to 0 and 1's.\n",
    "We convert X and y's as floats.\n",
    "\n",
    "Why self.y.reshape?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVDataset(Dataset):\n",
    "    def __init__(self,path):\n",
    "        dataframe = read_csv(path, header = None)\n",
    "        \n",
    "        self.X = dataframe.values[:,:-1]\n",
    "        self.y = dataframe.values[:,-1]\n",
    "        \n",
    "        self.X = self.X.astype('float32')\n",
    "        self.y = LabelEncoder().fit_transform(self.y)\n",
    "        self.y = self.y.astype('float32')\n",
    "        print(self.y.shape)\n",
    "        self.y = self.y.reshape(len(self.y),1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx],self.y[idx]]\n",
    "    \n",
    "    def get_split_data(self,n_train = 0.67):\n",
    "        train_len = round(len(self.X)*n_train)\n",
    "        test_len = len(self.X) - train_len\n",
    "        return random_split(self,[train_len,test_len])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition\n",
    "Linear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Module):\n",
    "    def __init__(self, inputs):\n",
    "        super(MLP,self).__init__()\n",
    "        \n",
    "        self.hidden1 = Linear(inputs,10)\n",
    "        kaiming_uniform_(self.hidden1.weight,nonlinearity = 'relu')\n",
    "        self.act1 = ReLU()\n",
    "        \n",
    "        self.hidden2 = Linear(10,8)\n",
    "        kaiming_uniform_(self.hidden2.weight, nonlinearity = 'relu')\n",
    "        self.act2 = ReLU()\n",
    "        \n",
    "        self.hidden3 = Linear(8,1)\n",
    "        xavier_uniform_(self.hidden3.weight)\n",
    "        self.act3 = Sigmoid()\n",
    "        \n",
    "    def forward(self,X):\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "        \n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        \n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path):\n",
    "    dataset = CSVDataset(path)\n",
    "    train_data, test_data = dataset.get_split_data()\n",
    "    train_dl = DataLoader(train_data,batch_size = 32, shuffle = True)\n",
    "    test_dl = DataLoader(test_data, batch_size = 1024, shuffle = False)\n",
    "    \n",
    "    return train_dl, test_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,train_dl):\n",
    "    criterion = BCELoss()\n",
    "    optimizer = SGD(model.parameters(),lr = 0.01, momentum =0.9)\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        for i,(inputs,target) in enumerate(train_dl):\n",
    "            optimizer.zero_grad()\n",
    "            yhat = model(inputs)\n",
    "            loss = criterion(yhat,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,test_dl):\n",
    "    prediction, actual = list(),list()\n",
    "    for i,(inputs,target) in enumerate(test_dl):\n",
    "        yhat = model(inputs)\n",
    "        \n",
    "        yhat = yhat.detach().numpy()\n",
    "        yhat = yhat.round()\n",
    "        \n",
    "        y = target.numpy()\n",
    "        y = y.reshape(len(y),1)\n",
    "        \n",
    "        prediction.append(yhat)\n",
    "        actual.append(y)\n",
    "    prediction, actual = vstack(prediction), vstack(actual)\n",
    "    \n",
    "    acc = accuracy_score(actual,prediction)\n",
    "    return acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(row,model):\n",
    "    row = Tensor([row])\n",
    "    yhat = model(row)\n",
    "    yhat = yhat.detach().numpy()\n",
    "    return yhat    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351,)\n",
      "235 116\n",
      "Accuracy  0.8448275862068966\n",
      "Predicted: 0.989 (class=1)\n",
      "Predicted: 0.014 (class=0)\n"
     ]
    }
   ],
   "source": [
    "path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data\"\n",
    "train_dl, test_dl = prepare_data(path)\n",
    "print(len(train_dl.dataset), len(test_dl.dataset))\n",
    "\n",
    "model = MLP(34)\n",
    "\n",
    "train_model(model,train_dl)\n",
    "\n",
    "acc = evaluate_model(model,test_dl)\n",
    "print(\"Accuracy \", acc)\n",
    "\n",
    "row = [1,0,1,0.06655,1,-0.18388,1,-0.27320,1,-0.43107,1,-0.41349,0.96232,-0.51874,0.90711,-0.59017,0.89230,-0.66474,0.69876,-0.70997,0.70645,-0.76320,0.63081,-0.80544,0.55867,-0.89128,0.47211,-0.86500,0.40303,-0.83675,0.30996,-0.89093,0.22995,-0.89158]\n",
    "yhat = predict(row,model)\n",
    "print('Predicted: %.3f (class=%d)' % (yhat, yhat.round()))\n",
    "\n",
    "row = [1,0,0.71253,-0.02595,0.41287,-0.23067,0.98019,-0.09473,0.99709,-0.10236,1,-0.10951,0.58965,1,0.83726,-1,0.82270,-0.17863,0.80760,-0.28257,-0.25914,0.92730,0.51933,0.05456,0.65493,-0.20392,0.93124,-0.41307,0.63811,-0.21901,0.86136,-0.87354,-0.23186,-1]\n",
    "yhat = predict(row,model)\n",
    "print('Predicted: %.3f (class=%d)' % (yhat, yhat.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
